<div align="center">

<!-- Styled Header matching app's welcome screen -->
<br/>

<img src="https://readme-typing-svg.demolab.com?font=Space+Grotesk&weight=700&size=50&duration=3000&pause=1000000000&color=22D3EE&center=true&vCenter=true&width=600&lines=AI+Code+Executor" alt="AI Code Executor"/>

<br/>

<img src="https://readme-typing-svg.demolab.com?font=DM+Sans&size=20&duration=4000&pause=500&color=888888&center=true&vCenter=true&width=600&lines=Execute+code+with+AI+assistance;in+secure+Docker+containers;Export+and+share+your+environments" alt="Subtitle"/>

<br/><br/>

<!-- Feature badges in cyan/turquoise style -->
<img src="https://img.shields.io/badge/ğŸ³_Docker_Isolated-0891b2?style=for-the-badge&labelColor=0a0a0b" alt="Isolated"/>
<img src="https://img.shields.io/badge/âš¡_Auto--Execute-22d3ee?style=for-the-badge&labelColor=0a0a0b" alt="Powerful"/>
<img src="https://img.shields.io/badge/ğŸ”§_Auto--Fix_Loop-0891b2?style=for-the-badge&labelColor=0a0a0b" alt="Auto-Fix"/>
<img src="https://img.shields.io/badge/ğŸ“¦_Export_Images-22d3ee?style=for-the-badge&labelColor=0a0a0b" alt="Export"/>
<img src="https://img.shields.io/badge/ğŸ–¥ï¸_Full_Terminal-0891b2?style=for-the-badge&labelColor=0a0a0b" alt="Terminal"/>

<br/><br/>

<!-- Provider badges -->
<img src="https://img.shields.io/badge/Claude_4-22d3ee?style=flat-square&logo=anthropic&logoColor=white&labelColor=0a0a0b" alt="Claude"/>
<img src="https://img.shields.io/badge/GPT--5.1-22d3ee?style=flat-square&logo=openai&logoColor=white&labelColor=0a0a0b" alt="GPT-5.1"/>
<img src="https://img.shields.io/badge/Gemini_2.5-22d3ee?style=flat-square&logo=google&logoColor=white&labelColor=0a0a0b" alt="Gemini"/>
<img src="https://img.shields.io/badge/Ollama-22d3ee?style=flat-square&logoColor=white&labelColor=0a0a0b" alt="Ollama"/>
<img src="https://img.shields.io/badge/Whisper_Voice-22d3ee?style=flat-square&logoColor=white&labelColor=0a0a0b" alt="Whisper"/>
<img src="https://img.shields.io/badge/FREE_Local_AI-10b981?style=flat-square&labelColor=0a0a0b" alt="Free"/>

<br/><br/>

<img width="1352" height="688" alt="AI Code Executor Interface" src="https://github.com/user-attachments/assets/d4da3b92-ec43-4a69-845e-cd285d0d9171" />

<br/><br/>

<!-- Navigation buttons styled like app -->
<a href="#-quick-start"><img src="https://img.shields.io/badge/â–¶_Quick_Start-22d3ee?style=for-the-badge&labelColor=0a0a0b" alt="Quick Start"/></a>
&nbsp;
<a href="#-docker-containers"><img src="https://img.shields.io/badge/ğŸ³_Docker-0891b2?style=for-the-badge&labelColor=0a0a0b" alt="Docker"/></a>
&nbsp;
<a href="#-docker-image-export"><img src="https://img.shields.io/badge/ğŸ“¦_Export-22d3ee?style=for-the-badge&labelColor=0a0a0b" alt="Export"/></a>
&nbsp;
<a href="#-ai-providers"><img src="https://img.shields.io/badge/ğŸ¤–_AI_Providers-0891b2?style=for-the-badge&labelColor=0a0a0b" alt="AI"/></a>
&nbsp;
<a href="#-auto-fix-system"><img src="https://img.shields.io/badge/ğŸ”§_Auto--Fix-22d3ee?style=for-the-badge&labelColor=0a0a0b" alt="Auto-Fix"/></a>
&nbsp;
<a href="#%EF%B8%8F-configuration"><img src="https://img.shields.io/badge/âš™ï¸_Config-0891b2?style=for-the-badge&labelColor=0a0a0b" alt="Config"/></a>

</div>

<br/>

---

<br/>

## âš¡ The Difference

<table>
<tr>
<td width="50%">

### ğŸ˜© Traditional Workflow
```
1. Ask AI for code
2. Copy code manually
3. Open terminal
4. Paste and run
5. See error
6. Copy error back to AI
7. Repeat 5-10 times...

â±ï¸ ~5 minutes per task
```

</td>
<td width="50%">

### âš¡ AI Code Executor
```
1. Ask AI for code
âœ… Auto-executed in Docker
âœ… Errors auto-detected
âœ… Auto-fixed (up to 10x)
âœ… Results displayed
âœ… Full terminal access
âœ… Export & share containers

â±ï¸ ~30 seconds per task
```

</td>
</tr>
</table>

<br/>

---

<br/>

## ğŸ³ Docker Containers

### Every Conversation Gets Its Own Isolated Container

When you start a new chat, a **dedicated Docker container** is automatically created just for that conversation. Your code runs in complete isolation - safe, secure, and reproducible.

#### ğŸ“¦ Pre-installed Tools

| Languages | Package Managers | Build Tools |
|-----------|------------------|-------------|
| ğŸ Python 3.11 | ğŸ“¦ pip / pip3 | ğŸ”§ gcc / g++ |
| ğŸŸ¢ Node.js 18 | ğŸ“¦ npm / yarn | ğŸ”§ make / cmake |
| ğŸ¦€ Rust (rustc) | ğŸ“¦ cargo | ğŸ”§ git |
| ğŸ’ Ruby | ğŸ“¦ gem | ğŸ”§ curl / wget |
| ğŸ¹ Go | ğŸ“¦ go mod | ğŸ”§ vim / nano |
| â˜• Java (OpenJDK) | ğŸ“¦ maven | ğŸ”§ jq / yq |

#### âš¡ Container Features

| Feature | Description |
|---------|-------------|
| ğŸ’» **Full Bash Shell** | Complete Linux environment |
| ğŸŒ **Internet Access** | Download packages, fetch data |
| ğŸ“ **Persistent Files** | Files persist during conversation |
| ğŸ“¦ **Exportable** | Save entire container as portable image |

#### ğŸ›ï¸ Resource Limits (Configurable)

| Resource | Range | Default |
|----------|-------|---------|
| CPU Cores | 1-16 | 2 |
| Memory | 512MB - 32GB | 8GB |
| Storage | 1GB - 100GB | 10GB |
| Timeout | 0-3600s | 30s (0 = unlimited) |

### ğŸ–¥ï¸ Built-in Web Terminal

**Full terminal access directly in your browser** - no SSH needed, no port forwarding, just click and type.

```bash
root@container:~$ python --version
Python 3.11.9

root@container:~$ node --version
v18.19.0

root@container:~$ pip install pandas numpy matplotlib
Successfully installed pandas-2.2.0 numpy-1.26.4 matplotlib-3.8.3

root@container:~$ ls -la
total 16
drwxr-xr-x 1 root root 4096 Jan 15 10:30 .
-rw-r--r-- 1 root root 2048 Jan 15 10:30 script.py
-rw-r--r-- 1 root root 8192 Jan 15 10:30 data.csv
```

**Terminal Features:**
- ğŸªŸ **Multi-tab support** - One terminal per conversation
- â†”ï¸ **Drag & resize** - Floating window you can move around
- ğŸ¨ **Full color support** - Syntax highlighting, colored output
- âŒ¨ï¸ **Keyboard shortcuts** - Ctrl+C, Ctrl+D, arrow keys, tab completion
- ğŸ“œ **Scrollback history** - Review previous commands
- ğŸ”„ **Persistent session** - Terminal stays open while chatting

### ğŸ“¦ Docker Image Export

**Take your work anywhere** - Export any conversation's container as a portable Docker image.

Built something cool? Export it and run it on another machine, share it with colleagues, or keep it as a backup.

#### How It Works

1. Click the ğŸ³ button on any conversation
2. Confirm the export
3. Download the `.tar` file from the Images panel

#### On Another Machine

```bash
# Load the exported image
docker load < my-project_2025-01-15_143052.tar

# Run it
docker run -it my-project_2025-01-15_143052:latest bash

# You're back in your exact environment!
root@container:/workspace$ ls
script.py  data.csv  results/
```

#### Features

| Feature | Description |
|---------|-------------|
| ğŸ³ **One-Click Export** | Export button on every conversation |
| ğŸ“ **Image Manager** | View, download, delete exported images |
| âš™ï¸ **Custom Path** | Configure export location in Settings |
| ğŸ“¦ **Full Environment** | Includes all files, packages, and state |

#### Configuration

Set custom export path in Settings â†’ Docker â†’ Image Export Path  
Or via environment variable: `DOCKER_EXPORT_PATH=./docker_images_exported`

<br/>

---

<br/>

## ğŸ¤– AI Providers

### 5 AI Providers - Choose Your Favorite (or Use Them All!)

<table>
<tr>
<td width="20%" align="center">

**ğŸŸ£ Anthropic**

<img src="https://img.shields.io/badge/Claude_4-6366f1?style=for-the-badge&labelColor=0a0a0b" alt="Claude"/>

Claude 4 Opus
Claude 4 Sonnet
Claude 3.5 Sonnet
Claude 3.5 Haiku

*Best reasoning*

</td>
<td width="20%" align="center">

**ğŸŸ¢ OpenAI**

<img src="https://img.shields.io/badge/GPT--5.1-10a37f?style=for-the-badge&labelColor=0a0a0b" alt="GPT"/>

GPT-5.1
GPT-5 / Mini
GPT-4.1 / Mini
GPT-4o / Mini

*Latest & greatest*

</td>
<td width="20%" align="center">

**ğŸ”µ Google**

<img src="https://img.shields.io/badge/Gemini_2.5-4285f4?style=for-the-badge&labelColor=0a0a0b" alt="Gemini"/>

Gemini 2.5 Pro
Gemini 2.5 Flash
Gemini 2.5 Flash-Lite
Gemini 2.0 Flash

*Fast & affordable*

</td>
<td width="20%" align="center">

**âš« Ollama**

<img src="https://img.shields.io/badge/Local_AI-000000?style=for-the-badge&labelColor=0a0a0b" alt="Ollama"/>

Llama 3 (8B/70B)
CodeLlama
Mistral
DeepSeek Coder

*100% FREE*
*100% Private*

</td>
<td width="20%" align="center">

**ğŸ¤ Whisper**

<img src="https://img.shields.io/badge/Voice_Input-22d3ee?style=for-the-badge&labelColor=0a0a0b" alt="Whisper"/>

Local Whisper
Remote GPU Server

*Talk to code*

</td>
</tr>
</table>

### ğŸ¦™ Ollama Integration - Free Local AI

Run AI **completely locally** - no API keys, no costs, no data leaving your machine.

```bash
# Install Ollama (one command)
curl -fsSL https://ollama.ai/install.sh | sh   # Linux
brew install ollama                             # macOS

# Pull models
ollama pull llama3           # General purpose (8B)
ollama pull llama3:70b       # More powerful (70B)
ollama pull codellama        # Optimized for code
ollama pull deepseek-coder   # Code specialist
ollama pull mistral          # Fast & efficient

# Models auto-detected in AI Code Executor!
```

**Ollama Features:**
- âœ… **Auto-detection** - Models appear in dropdown automatically
- âœ… **No API key needed** - Just install and go
- âœ… **Offline capable** - Works without internet
- âœ… **Privacy first** - Your code never leaves your machine
- âœ… **Custom models** - Import any GGUF model

### ğŸ¤ Whisper Voice Integration

**Talk instead of type** - Whisper transcribes your voice to text in real-time.

| Option | Description |
|--------|-------------|
| **ğŸ–¥ï¸ Local Whisper** | Runs on your machine, requires Python + openai-whisper, works offline |
| **ğŸš€ Remote GPU Server** | Point to your Whisper server for faster GPU-accelerated transcription |

**Configuration:** Settings â†’ Features â†’ Whisper Server URL  
**Example:** `http://192.168.1.100:9000`

<br/>

---

<br/>

## ğŸ”§ Auto-Fix System

### Intelligent Error Detection & Automatic Repair

When your code fails, AI Code Executor doesn't just show you the error - it **automatically fixes it**.

#### Example: Auto-Fix in Action

> **You:** "Create a stock analysis dashboard"

| Step | Action | Result |
|------|--------|--------|
| 1 | ğŸ¤– AI generates code | Code created |
| 2 | âš¡ Executing in Docker | âŒ `ModuleNotFoundError: No module named 'pandas'` |
| 3 | ğŸ”§ **Auto-fix 1/10** | Installing pandas... |
| 4 | âš¡ Re-executing | âŒ `ModuleNotFoundError: No module named 'yfinance'` |
| 5 | ğŸ”§ **Auto-fix 2/10** | Installing yfinance... |
| 6 | âš¡ Re-executing | âŒ `ModuleNotFoundError: No module named 'plotly'` |
| 7 | ğŸ”§ **Auto-fix 3/10** | Installing plotly... |
| 8 | âš¡ Re-executing | âœ… **SUCCESS!** Dashboard displayed |

### Auto-Fix Configuration

| Setting | Description | Range | Default |
|---------|-------------|-------|---------|
| ğŸ”§ **Max Attempts** | How many times to retry fixing errors | 1-20 | 10 |
| â±ï¸ **Execution Timeout** | Maximum time per code execution | 0-3600s | 30s (0 = unlimited) |

**Location:** Settings â†’ Features

### Custom Auto-Fix Prompt

**Full control over how AI analyzes and fixes errors:**

```
The code execution failed with the following error:

{errors}

Analyze the error carefully and provide ONLY the fixed code.
Do not explain - just provide working code.
If dependencies are missing, install them first with pip/npm.
```

> ğŸ’¡ Use `{errors}` placeholder - it gets replaced with actual error output.

**Location:** Settings â†’ Prompts â†’ Auto-Fix Prompt Template

<br/>

---

<br/>

## âš™ï¸ Configuration

### ğŸ“ Custom System Prompts

**Shape how AI writes code for you:**

**Default prompt (optimized for code execution):**
```
You are a professional coder who provides complete, executable code solutions. 
Present only code, no explanatory text. Present code blocks in execution order. 
If dependencies are needed, install them first using a bash script.
```

**Example customizations you can add:**
- "Always use Python 3.11 features"
- "Prefer async/await patterns"
- "Include comprehensive error handling"
- "Add logging to all functions"
- "Use type hints everywhere"
- "Write unit tests for all code"

**Location:** Settings â†’ Prompts â†’ System Prompt

### ğŸ”‘ API Keys Configuration

| Provider | Key Format | Get Your Key |
|----------|------------|--------------|
| ğŸŸ£ **Anthropic** (Claude) | `sk-ant-api03-...` | [console.anthropic.com](https://console.anthropic.com/) |
| ğŸŸ¢ **OpenAI** (GPT) | `sk-...` | [platform.openai.com](https://platform.openai.com/) |
| ğŸ”µ **Google** (Gemini) | `AIza...` | [makersuite.google.com](https://makersuite.google.com/) |
| âš« **Ollama** | Auto-detected | [ollama.ai](https://ollama.ai/) |
| ğŸ¤ **Whisper** (Optional) | Server URL | Self-hosted |

**Location:** Settings â†’ API Keys

### ğŸ³ Docker Resource Limits

| Setting | Range | Default | Description |
|---------|-------|---------|-------------|
| **CPU Cores** | 1-16 | 2 | CPU cores per container |
| **Memory** | 512m-32g | 8g | RAM limit per container |
| **Storage** | 1g-100g | 10g | Disk space per container |
| **Network** | On/Off | On | Allow internet access |

**Actions:**
- ğŸ—‘ï¸ **Stop All Containers** - Stop all running containers
- ğŸ§¹ **Cleanup Unused** - Remove stopped containers

**Location:** Settings â†’ Docker

### Environment Variables (.env)

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”‘ API KEYS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANTHROPIC_API_KEY=sk-ant-...          # Claude models
OPENAI_API_KEY=sk-...                  # GPT models
GEMINI_API_KEY=AIza...                 # Gemini models

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¦™ OLLAMA (Local AI)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
OLLAMA_HOST=http://localhost:11434     # Local or remote Ollama server

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¤ WHISPER (Voice Input)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
WHISPER_SERVER_URL=                    # Remote Whisper GPU server (optional)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš¡ EXECUTION SETTINGS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DOCKER_EXECUTION_TIMEOUT=30            # Seconds (0 = unlimited)
AUTO_FIX_MAX_ATTEMPTS=10               # Retry attempts (1-20)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ³ DOCKER RESOURCE LIMITS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DOCKER_CPU_CORES=2                     # 1-16 cores
DOCKER_MEMORY_LIMIT=8g                 # 512m-32g RAM
DOCKER_STORAGE_LIMIT=10g               # 1g-100g disk
DOCKER_EXPORT_PATH=./docker_images_exported  # Where exported images are saved

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ PROMPTS (Customize AI behavior)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SYSTEM_PROMPT=You are a professional coder...
AUTO_FIX_PROMPT=The code failed with:\n\n{errors}\n\nProvide fixed code only.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ SERVER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HOST=0.0.0.0
PORT=8000
```

<br/>

---

<br/>

## ğŸ“ File Management

### Upload, Browse, Download - All In Browser

| File | Size | Actions |
|------|------|---------|
| ğŸ“„ script.py | 2.4 KB | ğŸ‘ï¸ View Â· â¬‡ï¸ Download |
| ğŸ“„ data.csv | 156 KB | ğŸ‘ï¸ View Â· â¬‡ï¸ Download |
| ğŸ“„ requirements.txt | 0.3 KB | ğŸ‘ï¸ View Â· â¬‡ï¸ Download |
| ğŸ“„ output.json | 12 KB | ğŸ‘ï¸ View Â· â¬‡ï¸ Download |
| ğŸ“ results/ | â€” | â†’ Browse |
| ğŸ“„ chart.png | 89 KB | ğŸ‘ï¸ View Â· â¬‡ï¸ Download |

**Actions:** ğŸ“¤ Upload Files Â· ğŸ“¥ Download All as ZIP

**Features:**
- ğŸ“¤ Drag & drop upload into containers
- ğŸ‘ï¸ Syntax-highlighted file preview
- â¬‡ï¸ Download individual files
- ğŸ“¥ Bulk download as ZIP
- â†©ï¸ Send output to AI input (one-click)
- ğŸ”’ Large file protection (>1MB shows warning)

<br/>

---

<br/>

## ğŸ“± Mobile Support

### Fully Responsive - Works on Any Device

<img align="left" width="300" alt="Mobile Interface" src="https://github.com/user-attachments/assets/323c8077-b54e-4668-839b-99de76e40271" />

<br/>

**Mobile Features:**
- ğŸ“± Touch-optimized interface
- ğŸ” Collapsible sidebar
- âŒ¨ï¸ Keyboard-aware input area
- ğŸ¤ Voice input support

<br clear="left"/>

<br/>

---

<br/>

## ğŸš€ Quick Start

```bash
# Clone
git clone https://github.com/Ark0N/AI-Code-Executor.git

or

wget https://github.com/Ark0N/AI-Code-Executor/archive/refs/heads/main.zip
unzip main.zip

cd AI-Code-Executor

# Install (auto-detects OS & container runtime)
chmod +x INSTALL.sh && ./INSTALL.sh

# Start
./start.sh
```

<div align="center">

### ğŸŒ Open http://localhost:8000

</div>

<br/>

---

<br/>

## ğŸ“¦ Installation

### Supported Platforms

| Platform | Status | Notes |
|----------|--------|-------|
| Ubuntu / Debian | âœ… | apt |
| Fedora / RHEL | âœ… | dnf |
| Arch / Manjaro | âœ… | pacman |
| macOS Intel | âœ… | Homebrew |
| macOS Apple Silicon | âœ… | M1/M2/M3/M4 |
| Windows WSL2 | âœ… | Ubuntu recommended |

### Container Runtimes

| Runtime | Status |
|---------|--------|
| Docker Desktop | âœ… Recommended |
| Docker Engine | âœ… |
| Podman | âœ… |
| Colima | âœ… |

### ğŸ macOS

```bash
# Install Homebrew (if needed)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install Docker
brew install --cask docker    # Docker Desktop
# OR
brew install colima docker && colima start   # Colima (lightweight)
```

### ğŸ§ Linux

```bash
# Install Docker
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER
newgrp docker
```

<br/>

---

<br/>

## ğŸ”’ Security

- âœ… **Isolated Containers** - Each chat runs in separate Docker container
- âœ… **Resource Limits** - CPU, memory, storage caps prevent abuse
- âœ… **API Key Encryption** - Keys stored encrypted in database
- âœ… **No Host Access** - Code cannot escape container sandbox
- âœ… **Auto Cleanup** - Containers removed when done
- âœ… **Network Control** - Optional internet access restriction

<br/>

---

<br/>

## ğŸ“ Project Structure

```
AI-Code-Executor/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI app, auto-fix logic, endpoints
â”‚   â”œâ”€â”€ code_executor.py     # Docker container management
â”‚   â”œâ”€â”€ anthropic_client.py  # Claude API integration
â”‚   â”œâ”€â”€ openai_client.py     # GPT API integration
â”‚   â”œâ”€â”€ gemini_client.py     # Gemini API integration
â”‚   â”œâ”€â”€ ollama_client.py     # Local Ollama integration
â”‚   â”œâ”€â”€ whisper_client.py    # Local Whisper voice input
â”‚   â”œâ”€â”€ whisper_remote.py    # Remote Whisper GPU server
â”‚   â””â”€â”€ database.py          # SQLite async ORM
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html           # Main UI
â”‚   â”œâ”€â”€ app.js               # Application logic
â”‚   â””â”€â”€ style.css            # Styling
â”‚
â”œâ”€â”€ whisper/                 # Standalone Whisper server
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚
â”œâ”€â”€ INSTALL.sh               # Universal installer
â”œâ”€â”€ start.sh                 # Start server
â”œâ”€â”€ Dockerfile               # Container image
â””â”€â”€ .env.example             # Configuration template
```

<br/>

---

<br/>

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Make changes
4. Submit pull request

See [CONTRIBUTING.md](docs/development/CONTRIBUTING.md)

<br/>

---

<br/>

## ğŸ“ License

MIT License - see [LICENSE](LICENSE)

<br/>

---

<div align="center">

<br/>

<img src="https://readme-typing-svg.demolab.com?font=Space+Grotesk&weight=600&size=24&duration=3000&pause=1000&color=22D3EE&center=true&vCenter=true&width=400&lines=â­+Star+this+project!" alt="Star"/>

<br/>

If AI Code Executor saves you time, show some love!

<br/>

[![GitHub stars](https://img.shields.io/github/stars/Ark0N/AI-Code-Executor?style=for-the-badge&logo=github&color=22d3ee&labelColor=0a0a0b)](https://github.com/Ark0N/AI-Code-Executor/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/Ark0N/AI-Code-Executor?style=for-the-badge&logo=github&color=0891b2&labelColor=0a0a0b)](https://github.com/Ark0N/AI-Code-Executor/network/members)

<br/><br/>

### Built With

<img src="https://img.shields.io/badge/FastAPI-22d3ee?style=for-the-badge&logo=fastapi&logoColor=white&labelColor=0a0a0b" alt="FastAPI"/>
<img src="https://img.shields.io/badge/Docker-0891b2?style=for-the-badge&logo=docker&logoColor=white&labelColor=0a0a0b" alt="Docker"/>
<img src="https://img.shields.io/badge/Python-22d3ee?style=for-the-badge&logo=python&logoColor=white&labelColor=0a0a0b" alt="Python"/>
<img src="https://img.shields.io/badge/JavaScript-0891b2?style=for-the-badge&logo=javascript&logoColor=white&labelColor=0a0a0b" alt="JavaScript"/>

<br/><br/>

---

**Made with â¤ï¸ for developers who want AI that actually runs code**

**Coded with help of Claude AI (Sonnet 4.5 and Opus 4.5)**

**Â© 2025 AI Code Executor**

<br/>

</div>
